{
"question-1": "2019",
"question-2": "Simplified PROMISE Source Code (SPSC)\nPROMISE Source Code (PSC)",
"question-3": "SPSC: 6538 instances\nPSC: 14,066 instances",
"question-4": "Convolutional Neural Network (CNN) - proposed improved model\nDeep Belief Network (DBN) - used as baseline\nCNN -  Li's CNN model used as a baseline\nTraditional machine learning models - used as baselines for the PSC dataset:\n    * Decision Tree (DT)\n    * Logistic Regression (LR)\n    * Na√Øve Bayes (NB)\n    * Random Forest (RF)\n    * RBF Network (NET)\nRANDOM model - predicts buggy at a probability of 0.5\nFIX model - predicts all files as buggy",
"question-5": "Improved CNN: Outperformed traditional baselines and was comparable to DBN and Li's CNN on SPSC dataset. Achieved best average performance on PSC dataset across all metrics.\nDBN, Li's CNN: Comparable performance to the proposed CNN model, outperforming traditional methods.\nTraditional models (DT, LR, NB, RF, NET):  Outperformed by deep learning models on average, with RF being the closest competitor in MCC.\nRANDOM, FIX:  Performed poorly, indicating the effectiveness of other models.",
"question-6": "The study did not use traditional hand-crafted software metrics. Instead, it extracted features from Abstract Syntax Trees (ASTs) of source code.",
"question-7": "Not applicable as traditional software metrics weren't used. The focus was on automatically learning features from ASTs using deep learning.",
"question-8": "F-measure (F1-score)\nG-measure\nMatthews Correlation Coefficient (MCC)",
"question-9": "Not explicitly mentioned, but the word embedding layer within the CNN model inherently performs dimensionality reduction by representing words in a lower-dimensional space.",
"question-10": "Not used in this study, but suggested as a future research direction to address hyperparameter instability.",
"question-11": "SPSC dataset: 30-holdout repeated experiments\nPSC dataset: 10 x 10 cross-validation",
"question-12": "The exact ratio is not provided for each dataset, but the study mentions using random over-sampling to balance class distribution in the training set, achieving a 50:50 ratio of buggy and clean instances.",
"question-13": "Parsing source code into ASTs using javalang\nMapping string tokens to integers\nHandling class imbalance using random over-sampling\nDeleting infrequent tokens",
"question-14": "Performed implicitly by selecting 29 specific AST node types based on prior research and practical considerations.",
"question-15": "The study compared the proposed CNN model with:\n* Li's CNN model\n* DBN model\n* Traditional machine learning models (on PSC dataset)\n* RANDOM model\n* FIX model",
"question-16": "Python\nKeras (high-level API built on TensorFlow)",
"question-17": "Improved CNN: Strengths - Learns semantic representations from ASTs, good generalization. Weakness -  Sensitivity to hyperparameter instability.\nDBN, Li's CNN: Strengths - Ability to learn complex features from ASTs. Weaknesses - Performance variability, limited investigation of hyperparameter settings.\nTraditional models: Strengths - Simpler and faster to train. Weaknesses - Reliance on hand-crafted features, lower accuracy than deep learning models.",
"question-18": "The study focused on within-project defect prediction (WPDP).\nSPSC dataset used for cross-version WPDP\nPSC dataset used for within-version WPDP",
"question-19": "The study proposes an improved CNN model which incorporates elements from existing deep learning models, aiming for better generalization and feature extraction.",
"question-20": "Deep learning models (CNN, DBN) consistently outperformed traditional machine learning models for WPDP. The proposed improved CNN model demonstrated the best overall performance on the PSC dataset.",
"question-21": "Hyperparameter instability in deep learning models, leading to performance fluctuations.\nLimited generalizability of the findings to other datasets or programming languages.\nReliance on existing research for baseline model implementation, potentially introducing bias.",
"question-22": "Not explicitly analyzed, but the use of early stopping and setting a fixed number of epochs (50) suggests efforts to manage training time.",
"question-23": "Collecting more diverse datasets (C/C++, other domains).\nExploring different deep learning architectures (RNN).\nInvestigating the types of defects predictable by deep learning.\nDeveloping deep ensemble models to address hyperparameter instability.",
"question-24": "Not considered in this study.",
"question-25": "Yes, the study provides:\n* Workflow diagram of the software defect prediction process\n* CNN architecture diagram\n* Skip-gram model illustration\n* Dropout illustration\n* Proposed improved CNN model illustration\n* Graphs showing the impact of dense layers/nodes and kernel size/stride on F-measure.",
"question-26": "Not explicitly discussed, but the focus on automatically learning features from ASTs inherently makes interpretation more challenging compared to models using hand-crafted features.",
"question-27": "Not discussed, the focus is on academic research.",
"question-28": "Not analyzed in the study.",
"question-29": "The study directly uses ASTs as input, bypassing the need for traditional software metrics.",
"question-30": "The study acknowledges limitations in generalizing the results to other datasets or programming languages. Further research is needed to assess broader applicability."
}