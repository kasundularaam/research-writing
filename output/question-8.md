# QUESTION
What performance measures were used to evaluate the model(s)? (List all)

# Research 1

* **Primary:** Matthews Correlation Coefficient (MCC). The paper argues that this is a more unbiased measure for imbalanced data than F1 or AUC.
* **Additional:** Effect size (dominance) measured using Cliff's δ to quantify the practical significance of performance differences.

# Research 2

- Type I Accuracy (Specificity)
- Type II Accuracy (Sensitivity)
- Total Accuracy
- Area Under the ROC Curve (AUC-ROC)

# Research 3

The paper primarily uses visual analysis of the Bayesian posterior distributions.  Quantitative performance measures are not reported.

# Research 4

   - Primarily **F-measure** is used to compare the effectiveness of the different techniques.
   - Recall and Precision are also reported.

# Research 5

   * Accuracy
   * F-Measure
   * Normalized Estimated Fault Removal Cost (NEcost)

# Research 6

F-measure (F1-score)
G-measure
Matthews Correlation Coefficient (MCC)

# Research 7

["AUC-ROC", "G-mean"]

# Research 8

Recall, Precision, F-measure

# Research 9

Root Mean Square Error (RMSE)
Area Under the Receiver Operating Characteristic Curve (AUC-ROC)

# Research 10

* Accuracy
* F-measure (F1-score)
* Precision
* Recall
* Area Under ROC (Receiver Operating Characteristic) Curve (AUC)

# Research 11

* Confusion Matrix: To calculate True Positives, False Positives, True Negatives, False Negatives.
* Probability of Detection (PD) / Recall:  (TP / (TP + FN))
* Probability of False Alarms (PF): (FP / (FP + TN))
* ROC Curve: Visual representation of PD vs. PF.

# Research 12

PD (Probability of Detection), PF (Probability of False), F-measure, MCC (Matthews Correlation Coefficient), AUC (Area Under the ROC Curve)

# Research 13

The study used two performance measures:

* Area Under the ROC Curve (AUC)
* H-measure

# Research 14

Precision
Recall
Accuracy
Spearman Correlation
R-squared (R²)

# Research 15

The paper primarily uses accuracy as the performance measure.

# Research 16

- Accuracy
- Precision
- Recall
- F1-score
- ROC curve

# Research 17

Accuracy, Precision, Recall, F1-measure

# Research 18

g-mean, Accuracy

# Research 19

AUC-ROC, Hypervolume (HV), F1 score

# Research 20

The primary performance measure was the Area Under the ROC Curve (AUC-ROC).

# Research 21

* Accuracy (acc)
* Probability of detection (pd), which is equivalent to recall
* Probability of false alarms (pf)
* Balance (bal)
* Area Under the ROC Curve (AUC)
* Normalized Expected Cost of Misclassification (NECM)

# Research 22

* ROC (Receiver Operating Characteristic) curve
* AUC (Area Under the ROC Curve)
* H-measure 

# Research 23

* Precision
* Recall

# Research 24

Probability of Detection (pd) / Recall / Hit Rate
Probability of False Alarms (pf)
Balance (bal)
Precision (prec)

# Research 25

AUC (Area under the ROC curve)
g-mean (Geometric mean)
balance
pd (Recall)
pf (Probability of false alarms)

# Research 26

Primarily Area Under the Receiver Operating Characteristic curve (AUC-ROC).

# Research 27

AUC-ROC (Area Under the ROC Curve) is the primary measure.

# Research 28

* Sensitivity 
* Specificity 
* Precision 
* Completeness
* Area Under the ROC Curve (AUC-ROC)

# Research 29

Accuracy
F-measure
G-measure
Matthews Correlation Coefficient (MCC)

# Research 30

* Sensitivity
* Specificity
* Precision
* Completeness
* Area Under the ROC Curve (AUC-ROC)

